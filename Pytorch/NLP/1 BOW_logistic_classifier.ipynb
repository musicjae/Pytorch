{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BOW logistic classifier.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOvUrzT7rnnY7hfcdQ4z3FE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/musicjae/intro_to_python/blob/master/Pytorch/NLP/1%20BOW_logistic_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfyP-S6UVh7C"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "import torch.autograd as autograd"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRsdzP5-Yo-q"
      },
      "source": [
        "# Basic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZFORPAcWlzI",
        "outputId": "2357b06c-0136-429f-e5a9-34842e36a6a4"
      },
      "source": [
        "# By default, it concatenates along the first axis (concatenates rows)\r\n",
        "x_1 = torch.randn(2, 5)\r\n",
        "y_1 = torch.randn(3, 5)\r\n",
        "z_1 =torch.cat([x_1, y_1])\r\n",
        "print(z_1.shape)\r\n",
        "\r\n",
        "# Concatenate columns:\r\n",
        "x_2 = torch.randn(2, 3)\r\n",
        "y_2 = torch.randn(2, 5)\r\n",
        "z_2 = torch.cat([x_2, y_2], 1) # second arg specifies which axis to concat along\r\n",
        "print(z_2.shape)\r\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5, 5])\n",
            "torch.Size([2, 8])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1XQUL1kKWtBB",
        "outputId": "ee0bca26-6607-4bbf-ece5-868a836978c6"
      },
      "source": [
        "data = autograd.Variable(torch.randn(2,5))\r\n",
        "print(data)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.7870, -0.7939, -1.5257,  1.0286, -0.5081],\n",
            "        [ 0.4564, -1.0762,  0.4435, -0.7559, -0.4279]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRF2DELzXosg",
        "outputId": "cf1f7b24-588d-4eb0-fd3a-9ebd56ebf09d"
      },
      "source": [
        "lin = nn.Linear(5,3)\r\n",
        "print(lin(data))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.4148,  0.9644,  0.1419],\n",
            "        [-0.0628,  0.2385,  0.5309]], grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "181G1blEX6F3",
        "outputId": "6dc4e47e-9df7-456c-b549-47cf4afc2767"
      },
      "source": [
        "relu = F.relu\r\n",
        "print(relu(lin(data)))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.4148, 0.9644, 0.1419],\n",
            "        [0.0000, 0.2385, 0.5309]], grad_fn=<ReluBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwluwFpCX_xZ",
        "outputId": "e40d2e9a-c69a-4801-eb2f-a3732e994036"
      },
      "source": [
        "softmax = F.softmax\r\n",
        "print(softmax(relu(lin(data))))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.2862, 0.4959, 0.2179],\n",
            "        [0.2519, 0.3197, 0.4284]], grad_fn=<SoftmaxBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FarD_LeYL-g",
        "outputId": "f19cc9f5-54eb-4faf-ee09-f4919f149a0a"
      },
      "source": [
        "print(softmax(relu(lin(data))).sum())"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2., grad_fn=<SumBackward0>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeIbOy0nYqQr"
      },
      "source": [
        "# BOW 분류기 로지스틱 회귀"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "piR0vgrxd4mr"
      },
      "source": [
        "## data load"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBGnIGBBYejg"
      },
      "source": [
        "data = [ (\"이것 좀 주세요\".split(), \"KOREAN\"),\r\n",
        "         (\"Give it to me\".split(), \"ENGLISH\"),\r\n",
        "         (\"저는 엔지니어이면서 남자입니다\".split(), \"KOREAN\"),\r\n",
        "         (\"i am an engineer and a man\".split(), \"ENGLISH\") ]\r\n",
        "\r\n",
        "test_data = [ (\"당신은 화학자이면서 여자입니다\".split(), \"KOREAN\"),\r\n",
        "              (\"you are a chemist and a woman\".split(), \"ENGLISH\")]"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NGE_hbSd7LW"
      },
      "source": [
        "## preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pG9RRef5ZkkK",
        "outputId": "521871a3-3495-4b7d-c53d-843804d01247"
      },
      "source": [
        "w2i = {}\r\n",
        "for sent, _ in data + test_data:\r\n",
        "    for word in sent:\r\n",
        "        if word not in w2i:\r\n",
        "            w2i[word] = len(w2i) # 해당 단어를 w2i 길이에 맞는 위치에 추가\r\n",
        "print(w2i)\r\n",
        "\r\n",
        "VOCAB_SIZE = len(w2i)\r\n",
        "NUM_LABELS = 2"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'이것': 0, '좀': 1, '주세요': 2, 'Give': 3, 'it': 4, 'to': 5, 'me': 6, '저는': 7, '엔지니어이면서': 8, '남자입니다': 9, 'i': 10, 'am': 11, 'an': 12, 'engineer': 13, 'and': 14, 'a': 15, 'man': 16, '당신은': 17, '화학자이면서': 18, '여자입니다': 19, 'you': 20, 'are': 21, 'chemist': 22, 'woman': 23}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvJuBun6d86e"
      },
      "source": [
        "### utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u29Yl5MlbFcL"
      },
      "source": [
        "def make_bow_vector(sentence, w2i):\r\n",
        "    vec = torch.zeros(len(w2i))\r\n",
        "    for word in sentence:\r\n",
        "        vec[w2i[word]] += 1\r\n",
        "    return vec.view(1,-1)"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "br7UuYpscUgw",
        "outputId": "8f537865-48ef-4d60-e992-a9853359f377"
      },
      "source": [
        "sample = data[0]\r\n",
        "print(sample)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(['이것', '좀', '주세요'], 'KOREAN')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_Vrl3eIcWt5",
        "outputId": "f19d88d5-74ec-42ff-b548-35f4c8bb83e4"
      },
      "source": [
        "bow_vec = make_bow_vector(sample[0],w2i)\r\n",
        "print(bow_vec)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVz0MVy5dNx4",
        "outputId": "58892fa1-bf41-49d7-cd7a-6441ec67fefd"
      },
      "source": [
        "def make_target(label, l2i):\r\n",
        "    return torch.LongTensor([l2i[label]])\r\n",
        "\r\n",
        "l2i = {\"KOREAN\":0,\"ENGLISH\":1}\r\n",
        "\r\n",
        "print(make_target(\"KOREAN\",l2i))\r\n",
        "print(make_target(\"ENGLISH\",l2i))"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0])\n",
            "tensor([1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLPKUZEad-pI"
      },
      "source": [
        "## model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wegcunSBaAk6"
      },
      "source": [
        "class BOWclassifier(nn.Module):\r\n",
        "\r\n",
        "    def __init__(self, num_labels, vocab_size):\r\n",
        "        super(BOWclassifier, self).__init__()\r\n",
        "        self.linear = nn.Linear(vocab_size, 20)\r\n",
        "        self.linear2 = nn.Linear(20, num_labels)\r\n",
        "\r\n",
        "    def forward(self, bow_vec):\r\n",
        "        x = self.linear(bow_vec)\r\n",
        "        return F.log_softmax(self.linear2(x))"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrALC-Febrxa",
        "outputId": "3060e79d-c1f6-4dc2-e2db-75b73f3f7f77"
      },
      "source": [
        "model = BOWclassifier(NUM_LABELS, VOCAB_SIZE)\r\n",
        "print(model)\r\n",
        "for param in model.parameters():\r\n",
        "    print(param)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BOWclassifier(\n",
            "  (linear): Linear(in_features=24, out_features=20, bias=True)\n",
            "  (linear2): Linear(in_features=20, out_features=2, bias=True)\n",
            ")\n",
            "Parameter containing:\n",
            "tensor([[ 0.1008, -0.0088,  0.0349,  0.0218,  0.0110, -0.1446, -0.0102, -0.1457,\n",
            "         -0.1512, -0.0396,  0.0582,  0.1723,  0.0034,  0.1837, -0.1565, -0.1517,\n",
            "         -0.1809,  0.1751, -0.0250,  0.1489, -0.0736, -0.0637,  0.1422, -0.0862],\n",
            "        [-0.1511, -0.0398,  0.0529, -0.0959, -0.0276,  0.0439,  0.1453, -0.0961,\n",
            "         -0.1167,  0.0644,  0.1882,  0.1634,  0.0583,  0.0957, -0.2021,  0.0281,\n",
            "         -0.0463, -0.1694,  0.1184,  0.0372,  0.1803, -0.1806, -0.1760, -0.0853],\n",
            "        [-0.1885,  0.1083, -0.0040,  0.0269, -0.1954,  0.0664, -0.1270, -0.2041,\n",
            "          0.0751, -0.0820, -0.0501,  0.0088, -0.1081,  0.0890,  0.1328,  0.0715,\n",
            "          0.0532,  0.1309, -0.1666, -0.1345,  0.0463, -0.0879,  0.1044, -0.0895],\n",
            "        [-0.0703, -0.1788, -0.1004, -0.0073,  0.1989,  0.1627, -0.1136, -0.0922,\n",
            "         -0.1691,  0.0135, -0.1453,  0.1885, -0.0602,  0.1703, -0.0898, -0.0213,\n",
            "          0.0816, -0.1342,  0.1798, -0.0756, -0.1711, -0.0545,  0.0181,  0.1385],\n",
            "        [-0.1357,  0.1016, -0.1457,  0.1055, -0.0193,  0.1861, -0.0837, -0.1124,\n",
            "         -0.2015, -0.1180,  0.0379, -0.0883, -0.1103,  0.1694, -0.0945, -0.0467,\n",
            "          0.0203,  0.1690,  0.0804, -0.1921, -0.1901, -0.0650,  0.0356, -0.0935],\n",
            "        [-0.0319, -0.1551, -0.1775,  0.0004, -0.1042,  0.0045,  0.1631,  0.1961,\n",
            "          0.0533,  0.0965,  0.1143, -0.1086,  0.1721, -0.2019,  0.1704, -0.1323,\n",
            "          0.1245,  0.0775, -0.1952, -0.1652, -0.0844,  0.0190, -0.2006,  0.0408],\n",
            "        [-0.0193, -0.1169,  0.1272, -0.0519,  0.1456,  0.0977, -0.0596, -0.1968,\n",
            "          0.1708, -0.0226,  0.0115,  0.1943, -0.0895,  0.0629,  0.0166,  0.0612,\n",
            "          0.0030, -0.1918, -0.0428,  0.1662, -0.1590,  0.1311, -0.1462, -0.1440],\n",
            "        [-0.1089, -0.1801, -0.0331, -0.0201,  0.0203, -0.1424,  0.1408,  0.1149,\n",
            "         -0.1606,  0.0707,  0.0388,  0.2002,  0.0573,  0.0985,  0.1263,  0.1522,\n",
            "         -0.0693, -0.1446, -0.0124,  0.1449, -0.0467,  0.0724, -0.0852,  0.1145],\n",
            "        [ 0.0876,  0.1846,  0.1885,  0.0614, -0.0930, -0.1658,  0.0982, -0.0250,\n",
            "         -0.0802,  0.1495, -0.0233,  0.0915, -0.1216, -0.0581,  0.0439, -0.2034,\n",
            "         -0.0381,  0.0385, -0.0709, -0.1659, -0.1030,  0.1190,  0.1266, -0.0720],\n",
            "        [ 0.0890,  0.0041, -0.0107, -0.1095,  0.0819,  0.0588,  0.0988,  0.1934,\n",
            "         -0.1982, -0.0079, -0.0010, -0.0739, -0.0034, -0.0219, -0.0611, -0.0286,\n",
            "         -0.1269,  0.1936,  0.1707,  0.0477,  0.0888,  0.0069, -0.0485,  0.0117],\n",
            "        [-0.1372, -0.1726,  0.1744,  0.1641, -0.1108, -0.0868,  0.1219,  0.1931,\n",
            "         -0.0695, -0.1945, -0.0295,  0.1141, -0.1438, -0.1415,  0.0022,  0.1484,\n",
            "          0.1851, -0.0570, -0.1901, -0.1010, -0.1566,  0.0832,  0.0283,  0.0167],\n",
            "        [-0.1913, -0.0583,  0.1320,  0.1538,  0.1769, -0.0395, -0.0436, -0.1862,\n",
            "         -0.1817,  0.1191, -0.1085, -0.0339, -0.0243,  0.0607,  0.1865,  0.0715,\n",
            "          0.1963, -0.1597,  0.1930,  0.1478, -0.1603, -0.0145,  0.1005,  0.1607],\n",
            "        [ 0.0311, -0.0496, -0.0712, -0.1045,  0.0496,  0.0921, -0.0300,  0.0956,\n",
            "         -0.1805, -0.1431, -0.1004,  0.1749, -0.0976, -0.0593,  0.0356, -0.1925,\n",
            "         -0.1936, -0.1152, -0.0479, -0.1390, -0.2024,  0.0581, -0.0957, -0.0375],\n",
            "        [-0.0504,  0.0923,  0.0058,  0.1732, -0.1326, -0.0080, -0.1542,  0.0838,\n",
            "         -0.0214,  0.1249,  0.1161,  0.0046,  0.0887, -0.1704, -0.0040, -0.0548,\n",
            "         -0.0551,  0.0511,  0.0763, -0.0562,  0.2028, -0.1738, -0.0029, -0.1365],\n",
            "        [ 0.0745, -0.0491,  0.1691,  0.0367,  0.1576,  0.0575, -0.0653, -0.0652,\n",
            "          0.1120,  0.1862, -0.1035, -0.1702,  0.1335, -0.1479,  0.0583,  0.1439,\n",
            "         -0.0215,  0.1303, -0.2004,  0.1413, -0.0359, -0.1100,  0.2000, -0.2004],\n",
            "        [-0.0100, -0.1710, -0.1707,  0.1627, -0.1209,  0.0401, -0.1817,  0.1539,\n",
            "         -0.1312,  0.1253, -0.0999,  0.0460,  0.0963,  0.1078,  0.0433, -0.0382,\n",
            "          0.1318, -0.0683,  0.0490, -0.0051, -0.0300,  0.1969,  0.0083,  0.1909],\n",
            "        [-0.0622,  0.0693,  0.0527,  0.0704,  0.1558, -0.0049, -0.1525,  0.1846,\n",
            "         -0.0125, -0.1593,  0.0916,  0.0508,  0.1090, -0.0729, -0.1094, -0.1890,\n",
            "         -0.1049, -0.0468, -0.1882, -0.0601,  0.1369, -0.1958,  0.0840,  0.0832],\n",
            "        [-0.1705, -0.0480, -0.0584, -0.1301, -0.1470,  0.1742, -0.1427,  0.0531,\n",
            "         -0.1449,  0.0195,  0.1532, -0.1653,  0.0737,  0.1495, -0.1369, -0.1681,\n",
            "          0.0298, -0.0011, -0.1685, -0.0530,  0.0524,  0.0319, -0.0807, -0.0362],\n",
            "        [ 0.0253, -0.1051,  0.1835,  0.2004, -0.1944, -0.0607,  0.1053, -0.0383,\n",
            "         -0.1351,  0.1957, -0.0384,  0.0553,  0.1959, -0.0713, -0.1552,  0.0536,\n",
            "         -0.1188,  0.0845, -0.0560, -0.0205,  0.1360, -0.0556,  0.1976, -0.0755],\n",
            "        [ 0.0204,  0.1140,  0.0096,  0.1826, -0.0716,  0.0442,  0.1563,  0.1720,\n",
            "          0.1580, -0.1525, -0.1977,  0.0764,  0.1597, -0.0490,  0.1001,  0.1743,\n",
            "         -0.1803,  0.0313, -0.0567,  0.0816, -0.1366, -0.1996,  0.0472, -0.1511]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([ 1.7468e-01, -2.4921e-02, -1.8586e-01, -1.0284e-01, -1.4844e-01,\n",
            "         1.2854e-01, -1.1482e-01,  1.6541e-01, -7.1443e-05,  6.2100e-02,\n",
            "         6.2908e-02, -9.7095e-02,  1.4227e-01, -1.5996e-02, -3.6192e-02,\n",
            "         4.3519e-02, -1.3388e-01, -1.4012e-02, -1.1239e-01, -5.1183e-02],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[ 0.1774, -0.0146,  0.1679, -0.2000,  0.1200, -0.0740, -0.1482, -0.1417,\n",
            "         -0.0096,  0.1628,  0.0048,  0.0627, -0.0131, -0.1635,  0.1441,  0.0971,\n",
            "         -0.1727, -0.1263,  0.0583,  0.2188],\n",
            "        [-0.0795, -0.0614, -0.1360, -0.1382,  0.1587, -0.0397,  0.0527, -0.2213,\n",
            "          0.0146,  0.1801, -0.2161, -0.1593, -0.0656, -0.0785, -0.1375, -0.1272,\n",
            "          0.1489,  0.1782, -0.1640, -0.0158]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0700, -0.0641], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvliTx-2eX4U"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_IdqqAreZFe",
        "outputId": "55959afe-7ec3-46d1-86e9-2263ca62f3f5"
      },
      "source": [
        "lossfn = nn.NLLLoss()\r\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr= 0.1)\r\n",
        "\r\n",
        "losses=[]\r\n",
        "epochs=[]\r\n",
        "\r\n",
        "for epoch in range(200):\r\n",
        "\r\n",
        "    for instance, label in data:\r\n",
        "\r\n",
        "        # grad가 계속 축적 되니까 epoch이 반복될 때마다 초기화해준다\r\n",
        "        model.zero_grad()\r\n",
        "        # 자연어로 이루어진 데이터를 정수로 인코딩해준다\r\n",
        "        bow_vec = autograd.Variable(make_bow_vector(instance, w2i))\r\n",
        "        target = autograd.Variable(make_target(label, l2i))\r\n",
        "\r\n",
        "        # 모델 통과\r\n",
        "        predictions = model(bow_vec)\r\n",
        "\r\n",
        "        # get loss and update\r\n",
        "        loss = lossfn(predictions, target)\r\n",
        "        loss.backward()\r\n",
        "        optimizer.step()\r\n",
        "    if epoch % 10 == 0:\r\n",
        "\r\n",
        "        epochs.append(epoch)\r\n",
        "        losses.append(loss.item())\r\n",
        "        \r\n",
        "        print(f'epoch: {epoch}')    \r\n",
        "        print(f'loss: {loss.item()}')"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 0\n",
            "loss: 0.39296555519104004\n",
            "epoch: 10\n",
            "loss: 0.0\n",
            "epoch: 20\n",
            "loss: 0.0\n",
            "epoch: 30\n",
            "loss: 0.0\n",
            "epoch: 40\n",
            "loss: 0.0\n",
            "epoch: 50\n",
            "loss: 0.0\n",
            "epoch: 60\n",
            "loss: 0.0\n",
            "epoch: 70\n",
            "loss: 0.0\n",
            "epoch: 80\n",
            "loss: 0.0\n",
            "epoch: 90\n",
            "loss: 0.0\n",
            "epoch: 100\n",
            "loss: 0.0\n",
            "epoch: 110\n",
            "loss: 0.0\n",
            "epoch: 120\n",
            "loss: 0.0\n",
            "epoch: 130\n",
            "loss: 0.0\n",
            "epoch: 140\n",
            "loss: 0.0\n",
            "epoch: 150\n",
            "loss: 0.0\n",
            "epoch: 160\n",
            "loss: 0.0\n",
            "epoch: 170\n",
            "loss: 0.0\n",
            "epoch: 180\n",
            "loss: 0.0\n",
            "epoch: 190\n",
            "loss: 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYci-Y74gmtp"
      },
      "source": [
        "## Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dldABJ38gmPG",
        "outputId": "7812abd2-848e-4188-ac25-d0751a2c8e6d"
      },
      "source": [
        "def unpack_list(*list):\r\n",
        "    for l in list:\r\n",
        "        return l\r\n",
        "\r\n",
        "\r\n",
        "for instance, label in test_data:\r\n",
        "    bow_vec = autograd.Variable(make_bow_vector(instance,w2i))\r\n",
        "    predictions = model(bow_vec)\r\n",
        "    pred = predictions[0]\r\n",
        "    print(pred)\r\n"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-0.8001, -0.5965], grad_fn=<SelectBackward>)\n",
            "tensor([-26.5033,   0.0000], grad_fn=<SelectBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "nL96wgzHf5z0",
        "outputId": "684df1d6-e763-4cc9-bbc9-ebea617b5e16"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "plt.plot(epochs,losses)\r\n",
        "plt.show()"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}